{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-16T09:29:39.119047Z",
     "start_time": "2025-10-16T09:29:38.546865Z"
    }
   },
   "source": [
    "@file:DependsOn(\"ai.koog:koog-agents-jvm:0.5.0\")\n",
    "%use serialization"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T09:31:40.830700Z",
     "start_time": "2025-10-16T09:31:40.773164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.koog.prompt.executor.clients.anthropic.AnthropicLLMClient\n",
    "import ai.koog.prompt.executor.llms.all.simpleAnthropicExecutor\n",
    "import ai.koog.prompt.executor.ollama.client.OllamaClient\n",
    "import ai.koog.prompt.executor.llms.all.simpleOllamaAIExecutor\n",
    "import ai.koog.prompt.llm.LLMCapability\n",
    "import ai.koog.prompt.llm.LLMProvider\n",
    "import ai.koog.prompt.llm.LLModel\n",
    "\n",
    "val ollama = OllamaClient()\n",
    "val anthropic = AnthropicLLMClient(System.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "val executor = simpleAnthropicExecutor(System.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "val GptOss = LLModel(\n",
    "    provider = LLMProvider.Ollama,\n",
    "    id = \"gpt-oss:20b\",\n",
    "    capabilities = listOf(\n",
    "        LLMCapability.Temperature,\n",
    "        LLMCapability.Schema.JSON.Standard,\n",
    "        LLMCapability.Tools,\n",
    "        LLMCapability.OpenAIEndpoint.Completions,\n",
    "        LLMCapability.OpenAIEndpoint.Responses,\n",
    "    ),\n",
    "    contextLength = 128_000,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T09:31:42.294574Z",
     "start_time": "2025-10-16T09:31:42.266872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val files = File(\".\").listFiles()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T09:36:42.135331Z",
     "start_time": "2025-10-16T09:36:32.385443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.koog.prompt.dsl.prompt\n",
    "import ai.koog.prompt.executor.clients.anthropic.AnthropicModels\n",
    "import ai.koog.prompt.structure.executeStructured\n",
    "import ai.koog.prompt.xml.xml\n",
    "import kotlinx.coroutines.Dispatchers\n",
    "import kotlinx.coroutines.async\n",
    "import kotlinx.coroutines.awaitAll\n",
    "import kotlinx.coroutines.runBlocking\n",
    "\n",
    "val summarised = runBlocking(Dispatchers.Default) {\n",
    "    files\n",
    "        .filter { it.isFile }\n",
    "        .take(5)\n",
    "        .map { file ->\n",
    "            async {\n",
    "                Pair(file.name, executor.execute(prompt(\"summarise\") {\n",
    "                    system {\n",
    "                        +\"Find all relevant project files. Ignore hidden files, git, and configuration related files\"\n",
    "                        +\"If content is irrelevant return an empty string \\\"\\\"\"\n",
    "                    }\n",
    "                    user {\n",
    "                        xml {\n",
    "                            tag(\"content\") {\n",
    "                                +\"${file.readText()}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }, AnthropicModels.Sonnet_4_5).single().content)\n",
    "            }\n",
    "        }.awaitAll()\n",
    "}\n",
    "summarised"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(PromptChain.ipynb, \"\"\n",
       "\n",
       "This is a Jupyter notebook file showing code execution and debugging, not a project source file. It contains runtime errors and experimental code for testing LLM integrations (Anthropic, Ollama). This is not relevant project content to index.), (.DS_Store, \"\"\n",
       "\n",
       "This appears to be a binary file (likely a .DS_Store file based on the \"DSDB\" signature), not a relevant project source code file. Binary files and system metadata files are not useful for code analysis.), (local.properties, \"\"\n",
       "\n",
       "This file is `local.properties`, which is a configuration file containing local machine-specific paths for Android development. As indicated by the header comment, it should not be checked into version control and contains information specific to local configuration. This is not relevant project content.), (.env.template, # Project Analysis\n",
       "\n",
       "This appears to be an environment configuration file (`.env`) for a **Ktor-based application** with the following integrations:\n",
       "\n",
       "## Technology Stack & Services\n",
       "\n",
       "### 1. **Backend Framework**\n",
       "- **Ktor** - Kotlin web framework\n",
       "\n",
       "### 2. **Database**\n",
       "- **PostgreSQL** database\n",
       "  - Database: `ktor_sample`\n",
       "  - User: `ktor_user`\n",
       "  - Password: `ktor_password`\n",
       "  - Port: `5433` (non-standard, likely to avoid conflicts)\n",
       "  - Connection URL provided\n",
       "\n",
       "### 3. **AI/LLM Integrations**\n",
       "- **OpenAI API** - For GPT models\n",
       "- **Anthropic API** - For Claude models\n",
       "\n",
       "### 4. **Observability/Monitoring**\n",
       "- **Langfuse** - LLM observability and analytics platform\n",
       "  - Running locally at `http://localhost:3000`\n",
       "  - Requires public and secret keys for authentication\n",
       "\n",
       "### 5. **External APIs**\n",
       "- **Google Maps API** - For location/mapping services\n",
       "\n",
       "## Project Purpose\n",
       "\n",
       "Based on the dependencies, this appears to be a **Kotlin/Ktor application** that:\n",
       "- Uses AI language models (OpenAI/Anthropic)\n",
       "- Tracks LLM usage and performance via Langfuse\n",
       "- Integrates location services via Google Maps\n",
       "- Stores data in PostgreSQL\n",
       "\n",
       "Possible use cases: AI-powered location services, chatbot with geographical features, or a backend service combining LLM capabilities with mapping functionality.), (gradlew, This file is a Gradle wrapper script - it's a build system configuration file, not a project source file. It's irrelevant for understanding the actual project functionality.\n",
       "\n",
       "\"\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T09:37:41.437133Z",
     "start_time": "2025-10-16T09:37:18.093612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val readme = runBlocking {\n",
    "    executor.execute(prompt(\"write-readme\") {\n",
    "        system {\n",
    "            +\"Write a meaningfull README.md for the summarisation of the project\"\n",
    "        }\n",
    "        user {\n",
    "            xml {\n",
    "                summarised.forEach { (name, summary) ->\n",
    "                    tag(name) { +summary }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }, AnthropicModels.Sonnet_4_5).single().content\n",
    "}\n",
    "readme"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# PromptChain\n",
       "\n",
       "A Kotlin/Ktor-based framework for building and orchestrating LLM (Large Language Model) workflows with built-in observability and multi-provider support.\n",
       "\n",
       "## ğŸ¯ Overview\n",
       "\n",
       "PromptChain is a robust backend framework that enables developers to create sophisticated AI-powered applications by chaining together LLM interactions, managing prompts, and tracking performance. Built on top of Ktor, it provides a production-ready foundation for building AI services with enterprise-grade observability.\n",
       "\n",
       "## âœ¨ Key Features\n",
       "\n",
       "- **Multi-LLM Provider Support**: Seamlessly integrate with multiple AI providers:\n",
       "  - OpenAI (GPT models)\n",
       "  - Anthropic (Claude models)\n",
       "  - Ollama (local models)\n",
       "\n",
       "- **Chain-Based Architecture**: Build complex AI workflows by chaining multiple LLM calls together\n",
       "\n",
       "- **Built-in Observability**: Integrated Langfuse support for:\n",
       "  - LLM usage tracking\n",
       "  - Performance monitoring\n",
       "  - Cost analysis\n",
       "  - Debug traces\n",
       "\n",
       "- **Enterprise-Ready Stack**:\n",
       "  - PostgreSQL for persistent storage\n",
       "  - RESTful API architecture\n",
       "  - Environment-based configuration\n",
       "  - Kotlin coroutines for async operations\n",
       "\n",
       "- **Location Services**: Google Maps API integration for geo-aware AI applications\n",
       "\n",
       "## ğŸ› ï¸ Technology Stack\n",
       "\n",
       "- **Backend**: Ktor (Kotlin web framework)\n",
       "- **Database**: PostgreSQL\n",
       "- **AI Providers**: OpenAI, Anthropic, Ollama\n",
       "- **Observability**: Langfuse\n",
       "- **Additional Services**: Google Maps API\n",
       "\n",
       "## ğŸš€ Getting Started\n",
       "\n",
       "### Prerequisites\n",
       "\n",
       "- JDK 11 or higher\n",
       "- PostgreSQL 12+\n",
       "- Docker (optional, for Langfuse)\n",
       "\n",
       "### Installation\n",
       "\n",
       "1. **Clone the repository**\n",
       "   ```bash\n",
       "   git clone <repository-url>\n",
       "   cd promptchain\n",
       "   ```\n",
       "\n",
       "2. **Configure environment variables**\n",
       "   ```bash\n",
       "   cp .env.template .env\n",
       "   ```\n",
       "   \n",
       "   Edit `.env` and add your API keys:\n",
       "   - `OPENAI_API_KEY`: Your OpenAI API key\n",
       "   - `ANTHROPIC_API_KEY`: Your Anthropic API key\n",
       "   - `GOOGLE_MAPS_API_KEY`: Your Google Maps API key\n",
       "   - `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY`: Langfuse credentials\n",
       "\n",
       "3. **Set up the database**\n",
       "   ```bash\n",
       "   # Ensure PostgreSQL is running\n",
       "   # The default configuration expects:\n",
       "   # - Database: ktor_sample\n",
       "   # - User: ktor_user\n",
       "   # - Port: 5433\n",
       "   ```\n",
       "\n",
       "4. **Run Langfuse (optional, for observability)**\n",
       "   ```bash\n",
       "   # Langfuse expected at http://localhost:3000\n",
       "   docker-compose up langfuse\n",
       "   ```\n",
       "\n",
       "5. **Build and run the application**\n",
       "   ```bash\n",
       "   ./gradlew run\n",
       "   ```\n",
       "\n",
       "## ğŸ“‹ Use Cases\n",
       "\n",
       "PromptChain is ideal for building:\n",
       "\n",
       "- **AI-powered chatbots** with conversation history and context management\n",
       "- **Location-aware AI assistants** combining geospatial data with LLM reasoning\n",
       "- **Multi-step AI workflows** requiring orchestration of multiple LLM calls\n",
       "- **AI applications requiring observability** with detailed tracking and analytics\n",
       "- **Services needing multi-provider support** with fallback capabilities\n",
       "\n",
       "## ğŸ—ï¸ Architecture\n",
       "\n",
       "```\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚   Ktor Server   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "         â”‚\n",
       "    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”\n",
       "    â”‚  Chain  â”‚\n",
       "    â”‚ Manager â”‚\n",
       "    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
       "         â”‚\n",
       "    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "    â”‚                      â”‚\n",
       "â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚  LLM   â”‚          â”‚ Langfuse   â”‚\n",
       "â”‚Providerâ”‚          â”‚ Tracking   â”‚\n",
       "â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "    â”‚\n",
       "â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ OpenAI â”‚ Claude  â”‚\n",
       "â”‚ Ollama â”‚ etc.    â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "```\n",
       "\n",
       "## ğŸ” Observability\n",
       "\n",
       "All LLM interactions are automatically tracked via Langfuse, providing:\n",
       "- Request/response logging\n",
       "- Token usage metrics\n",
       "- Latency measurements\n",
       "- Cost tracking\n",
       "- Error monitoring\n",
       "\n",
       "Access the Langfuse dashboard at `http://localhost:3000` to view detailed analytics.\n",
       "\n",
       "## ğŸ“ Configuration\n",
       "\n",
       "Key configuration files:\n",
       "- `.env`: Environment variables and API keys\n",
       "- `local.properties`: Android/local development settings (machine-specific)\n",
       "- Database configuration in `.env`\n",
       "\n",
       "## ğŸ¤ Contributing\n",
       "\n",
       "Contributions are welcome! This project is in active development.\n",
       "\n",
       "## ğŸ“„ License\n",
       "\n",
       "[Add your license information here]\n",
       "\n",
       "## ğŸ”— Links\n",
       "\n",
       "- [Ktor Documentation](https://ktor.io/)\n",
       "- [Langfuse Documentation](https://langfuse.com/docs)\n",
       "- [OpenAI API](https://platform.openai.com/docs)\n",
       "- [Anthropic API](https://docs.anthropic.com/)\n",
       "\n",
       "---\n",
       "\n",
       "**Note**: This project is designed for building production-grade AI applications with proper observability and monitoring. Ensure all API keys are kept secure and never committed to version control."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-Beta2",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
